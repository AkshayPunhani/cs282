### Abstract 

The creation of sophisticated fake videos has been
largely relegated to Hollywood studios or sophisticated
state actors. Recent advances in deep learning,
however, have made it signicantly easier to create
sophisticated and compelling fake videos. With relatively
modest amounts of data and computing power,
the average person can, for example, create a video of
a world leader confessing to colluding with a foreign
government to win an election. These so called deep
fakes [1] pose a signicant threat to our democracy
and national security. To contend with this growing
threat, we want to develop a forensic technique
that models facial movements to typify a individual's
speaking pattern. Although not visually apparent,
these correlations are often violated by the nature of
how deep fake videos are created and can, therefore,
be used for authentication.
