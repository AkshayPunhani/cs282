{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating the dataframes from CSV's of 4 celebrities\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "biden = pd.read_csv(\"dataset/biden/real/\"+\"output.csv\")\n",
    "justin = pd.read_csv(\"dataset/justin/real/\"+\"output.csv\")\n",
    "#may = pd.read_csv(\"dataset/may/real/\"+\"output.csv\")\n",
    "pelosi = pd.read_csv(\"dataset/pelosi/real/\"+\"output.csv\")\n",
    "michelle = pd.read_csv(\"dataset/michelle/real/\"+\"output.csv\")\n",
    "\n",
    "biden['label'] = 0\n",
    "justin['label'] = 1\n",
    "#may['label'] = 'may'\n",
    "pelosi['label'] = 2\n",
    "michelle['label'] = 3\n",
    "\n",
    "df_merged = pd.concat([biden, justin, michelle, pelosi])\n",
    "Y = df_merged['label']\n",
    "X = df_merged.drop('label', axis =1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To incorporate for the timesteps 50, either we do some padding or get rid of some of the frames\n",
    "X_new= X.iloc[0:610250]\n",
    "Y = np.array(Y.iloc[0:610250])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/data.py:645: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/base.py:464: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, **fit_params).transform(X)\n"
     ]
    }
   ],
   "source": [
    "#Normalizing the input\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "X_new = StandardScaler().fit_transform(X_new)\n",
    "norm_X = np.array(X_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Defining the inputs for the LSTM\n",
    "timesteps = 50\n",
    "data_dim = 426\n",
    "num_classes = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reshaping the input matrix for the LSTM\n",
    "updated_X = np.reshape(norm_X, (int(norm_X.shape[0]/timesteps), 50, 426))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12205, 50, 426)"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#input shape for the LSTM\n",
    "updated_X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Preparing the target variable\n",
    "i=0\n",
    "count =0\n",
    "target = []\n",
    "for i in range(0,610249, 50):\n",
    "    z = np.argmax(np.bincount(Y[i:i+50]))\n",
    "    target.append(z)\n",
    "    count = count+1\n",
    "target = np.array(target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "#one hot encoding the target variable\n",
    "encoder = LabelEncoder()\n",
    "encoder.fit(target)\n",
    "encoded_Y = encoder.transform(target)\n",
    "# convert integers to dummy variables (i.e. one hot encoded)\n",
    "dummy_y = np_utils.to_categorical(encoded_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "#imports for the LSTM model in Keras\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from keras.utils import np_utils\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "from keras.layers import Dropout\n",
    "from keras.callbacks import TensorBoard\n",
    "from keras.models import load_model\n",
    "from keras.layers import LSTM, Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "# expected input data shape: (no of samples, timesteps, data_dim)\n",
    "model = Sequential()\n",
    "model.add(LSTM(426, return_sequences=True,\n",
    "               input_shape=(timesteps, data_dim)))  # returns a sequence of vectors of dimension 426\n",
    "model.add(LSTM(200, return_sequences=True))  # returns a sequence of vectors of dimension 200\n",
    "model.add(LSTM(32))  # return a single vector of dimension 32\n",
    "model.add(Dense(4, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "#compiling the LSTM model and the displaying the summary\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='rmsprop',\n",
    "              metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Splitting into train, test and validation\n",
    "X_train, X_test, y_train, y_test = train_test_split(updated_X, dummy_y, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 5723 samples, validate on 2454 samples\n",
      "Epoch 1/3\n",
      "5723/5723 [==============================] - 149s 26ms/step - loss: 0.1462 - acc: 0.9614 - val_loss: 0.0666 - val_acc: 0.9772\n",
      "Epoch 2/3\n",
      "5723/5723 [==============================] - 102s 18ms/step - loss: 0.0437 - acc: 0.9892 - val_loss: 0.0160 - val_acc: 0.9955\n",
      "Epoch 3/3\n",
      "5723/5723 [==============================] - 102s 18ms/step - loss: 0.0196 - acc: 0.9942 - val_loss: 0.0047 - val_acc: 0.9992\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x143ea7208>"
      ]
     },
     "execution_count": 224,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#fitting the data to the LSTM model and \n",
    "\n",
    "tensorboard = TensorBoard(log_dir='./logs', histogram_freq=0,\n",
    "                          write_graph=True, write_images=False)\n",
    "model.fit(X_train, y_train,\n",
    "          batch_size=64, validation_split=0.3, shuffle = True,  epochs=3, callbacks=[tensorboard])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [],
   "source": [
    "#saving the model, deleting from the memory and restoring it again\n",
    "model.save(\"lstm_facial.h5\")\n",
    "del model\n",
    "\n",
    "model = load_model(\"lstm_facial.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [],
   "source": [
    "#predicting on the test dataset\n",
    "y_pred = model.predict_classes(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4028"
      ]
     },
     "execution_count": 245,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#length of the predictions\n",
    "len(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#for decoding the one hot encoded input of the original test set\n",
    "lst = []\n",
    "def decode(datum):\n",
    "    return np.argmax(datum)\n",
    "\n",
    "for i in range(y_test.shape[0]):\n",
    "    lst.append(decode(y_test[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9985104270109235\n"
     ]
    }
   ],
   "source": [
    "#accuracy from the test set\n",
    "accuracy = (y_pred == np.array(lst)).mean()\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dropped_X = X.drop([X.columns[[1, 69]]], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
