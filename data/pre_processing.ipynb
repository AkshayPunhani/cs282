{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data pre-processing\n",
    "\n",
    "The main pre-processing is to save the frames, data landmarks, and audio to the hdf5 file format. There are three sections to this notebook given below. Each section outputs a hdf5 file with a separate group for each person label. In each hdf5 group a separate dataset is created for each video file. Each dataset shape is defined below.\n",
    "\n",
    "1) Extract raw grayscale frames: Each dataset has shape (number of frames in video, frame_sz_y, frame_sz_x). The frame size of raw image and the number of frames are given by frame_sz and out_fps*T, where T is the length of the video in seconds.\n",
    "\n",
    "2) Extract landmark, 3D head rotation, and intensity of action units: Each dataset has shape (number of frames in video, 156 (68 landmark x + 68 landmark y + 17 Action Units+ 3 head rotaion)). The number of frames per second are given by frame_sz and out_fps*T, where T is the length of the video in seconds. The landmarks are normalized and frontalized. \n",
    "\n",
    "3) Spectograms of audio: Each dataset is of shape (number of frames in the video, n_fft/2+1). The number of frames are given by (T-sfft_wl)/sfft_hop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#start by importing the libraries\n",
    "from IPython.display import clear_output\n",
    "%matplotlib inline\n",
    "import h5py\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import librosa\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "bsfldr = '/Users/shrutiagarwal/Documents/MATLAB/cs282/data/fakes/imposter/'#the basefolder to the dataset\n",
    "#not using anywhere\n",
    "seq_len = 5 #sequence of input length in seconds, this length will be the same for audio spectrogram as well\n",
    "\n",
    "#this is for video data\n",
    "in_fps = 30 #number of frames input per second\n",
    "out_fps = 10 #subsample the frames\n",
    "frame_sz = (128, 128) #the size of the image\n",
    "\n",
    "#audio feature, these params are picked from voxceleb paper\n",
    "sfft_wl = 0.025 #spectrogram window in seconds\n",
    "sfft_hop = 0.010 #hop length in seconds \n",
    "n_fft = 1024 # the size of the dataset is t x (n_fft/2+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/shrutiagarwal/opt/cs282/lib/python3.6/site-packages/ipykernel_launcher.py:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    subjects  label  file_count\n",
      "0     bernie      0          12\n",
      "1      biden      1           0\n",
      "2       diff      2           0\n",
      "3    hillary      3          28\n",
      "4     justin      4           5\n",
      "5        may      5           8\n",
      "6   michelle      6           0\n",
      "7       modi      7          19\n",
      "8      obama      8          21\n",
      "9     pelosi      9           0\n",
      "10     putin     10           0\n",
      "11     trump     11          24\n",
      "12    warren     12          10\n"
     ]
    }
   ],
   "source": [
    "def get_all_files(basefldr):\n",
    "    \n",
    "    # Get the list of all files in directory tree at given path\n",
    "    listOfFiles = {}\n",
    "    dirnames = [f for f in os.listdir(basefldr) if os.path.isdir(os.path.join(basefldr, f))]#all the subject names\n",
    "    dirnames = np.sort(dirnames)\n",
    "    \n",
    "    subject_lbl = pd.DataFrame() #store the mapping of labels and subjects\n",
    "    subject_lbl['subjects'] = dirnames\n",
    "    subject_lbl['label'] = np.arange(len(dirnames))\n",
    "    subject_lbl['file_count'] = 0    \n",
    "    i = 0\n",
    "    for d in dirnames:\n",
    "        listOfFiles[i] = np.sort(np.array([os.path.join(basefldr, d, os.path.splitext(f)[0]) \n",
    "                                  for f in os.listdir(os.path.join(basefldr, d)) if f.endswith('.mp4')]))\n",
    "\n",
    "        subject_lbl['file_count'][subject_lbl['label'] == i] = len(listOfFiles[i])\n",
    "        i = i+1\n",
    "    \n",
    "    print(subject_lbl)\n",
    "    subject_lbl.to_csv('subject_label.csv')\n",
    "    \n",
    "    return listOfFiles\n",
    "    \n",
    "file_paths = get_all_files(bsfldr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Raw Frames "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "#used to detect the face in the frames\n",
    "protoPath = os.path.sep.join(['face_detection_model', \"deploy.prototxt\"])\n",
    "modelPath = os.path.sep.join(['face_detection_model', \"res10_300x300_ssd_iter_140000.caffemodel\"])\n",
    "DETECTOR = cv2.dnn.readNetFromCaffe(protoPath, modelPath)\n",
    "\n",
    "#code to get the face in an RGB image\n",
    "def get_face(image, verbose=False):\n",
    "    \n",
    "    face = None\n",
    "    (h, w) = image.shape[:2]\n",
    "    # construct a blob from the image\n",
    "    imageBlob = cv2.dnn.blobFromImage(cv2.resize(image, (300, 300)), 1.0, (300, 300), (104.0, 177.0, 123.0), \n",
    "                                      swapRB=False, crop=False)\n",
    "    # apply OpenCV's deep learning-based face detector to localize faces in the input image\n",
    "    DETECTOR.setInput(imageBlob)\n",
    "    detections = DETECTOR.forward()\n",
    "    if len(detections) > 0: # ensure at least one face was found\n",
    "        # we're making the assumption that each image has only ONE\n",
    "        # face, so find the bounding box with the largest probability\n",
    "        i = np.argmax(detections[0, 0, :, 2])\n",
    "        box = detections[0, 0, i, 3:7] * np.array([w, h, w, h])\n",
    "        (startX, startY, endX, endY) = box.astype(\"int\")\n",
    "\n",
    "        # extract the face ROI and grab the ROI dimensions\n",
    "        face = image[startY:endY, startX:endX]\n",
    "        if verbose:\n",
    "            cv2.imshow(\"Frame\", face)\n",
    "            key = cv2.waitKey(1) & 0xFF\n",
    "    \n",
    "    return face\n",
    "\n",
    "#get all the frames in the video, preprocess as the following:\n",
    "#1 extract the rgb frame\n",
    "#2 convert to grayscale\n",
    "#3 reduce the size\n",
    "#4 reduce the temporal frequency\n",
    "def get_all_frames_video(in_file, in_fps, out_fps, frame_sz, verbose=False):\n",
    "    \n",
    "    avg_win = int(in_fps/out_fps)\n",
    "    #the number of frames we will get from this video\n",
    "    vidcap = cv2.VideoCapture(in_file + '.mp4') # read the mp4\n",
    "    in_frame_cnt = vidcap.get(cv2.CAP_PROP_FRAME_COUNT)\n",
    "    out_frame_cnt = int(in_frame_cnt*out_fps/in_fps)\n",
    "    out_faces = np.zeros((out_frame_cnt, frame_sz[0], frame_sz[1]))\n",
    "    count = 0\n",
    "\n",
    "    #this is used to do the running average\n",
    "    avg_win_faces = np.zeros((avg_win, frame_sz[0], frame_sz[1]))\n",
    "    avg_win_cnt = 0\n",
    "\n",
    "    success, image = vidcap.read() # extract the frames\n",
    "    while success:\n",
    "\n",
    "        face = get_face(image, verbose) # get the face rectangle\n",
    "        if face is not None:\n",
    "\n",
    "            face = np.mean(face, axis=2) # convert the face to grayscale\n",
    "            # reduce the frame size to frame_size (sz_x X sz_y X frames)\n",
    "            face = cv2.resize(face, dsize=frame_sz, interpolation=cv2.INTER_CUBIC)\n",
    "            face = face - np.min(face)\n",
    "            face = face/np.max(face) # the intensity is in 0-1\n",
    "\n",
    "            avg_win_faces[avg_win_cnt, :,:] = face.copy() #average window\n",
    "            avg_win_cnt += 1\n",
    "\n",
    "            if avg_win_cnt == avg_win:\n",
    "                out_faces[count, :, :] = np.mean(avg_win_faces, axis=2)\n",
    "                count += 1\n",
    "                # subsample the frames at a outfps rate\n",
    "                avg_win_faces = np.zeros((avg_win, frame_sz[0], frame_sz[1]))\n",
    "                avg_win_cnt = 0\n",
    "\n",
    "        success, image = vidcap.read() # extract the frames\n",
    "\n",
    "    if count < out_frame_cnt:\n",
    "        print('{} count: {}/{}'.format(v, count, out_frame_cnt))\n",
    "        print('max:{} min:{}'.format(np.max(out_faces), np.min(out_faces)))\n",
    "    out_faces = out_faces[:, :, :count]\n",
    "    \n",
    "    return out_faces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#frame hdf5\n",
    "h5file = h5py.File('rawframes.hdf5', 'a')\n",
    "lbls = list(file_paths.keys()) #hdf5 file will have a separate group for each label\n",
    "avg_win = int(in_fps/out_fps)\n",
    "for i in lbls:\n",
    "    \n",
    "    if str(i) in h5file.keys():\n",
    "        group = h5file[str(i)]\n",
    "    else:\n",
    "        group = h5file.create_group(str(i)) #create label specific group\n",
    "    vid_names = file_paths[i]\n",
    "    \n",
    "    for v in vid_names:\n",
    "        \n",
    "        db_name = v.split('/')[-1] # name of dataset\n",
    "        if db_name not in group.keys(): #do only if the file has not been processed\n",
    "\n",
    "            out_faces = get_all_frames_video(v, in_fps, out_fps, frame_sz, verbose=False)\n",
    "            \n",
    "            # display the frame\n",
    "            if False:\n",
    "                plt.imshow(out_faces[:, :, 10], cmap='gray')\n",
    "                plt.show()\n",
    "            \n",
    "            # create the dataset with the complete groups with chunksize \n",
    "            data = group.create_dataset(db_name, out_faces.shape, dtype='f4',\n",
    "                                        compression=\"gzip\", compression_opts=4)\n",
    "            data[:] = out_faces\n",
    "            h5file.flush() #write out the file\n",
    "\n",
    "h5file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Facial Landmarks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#code to get the face in an RGB image\n",
    "def get_landmark(csv_file, verbose=False):\n",
    "    \n",
    "    x = np.array(csv_file.loc[:, ' X_0':' X_67'])\n",
    "    y = np.array(csv_file.loc[:, ' Y_0':' Y_67'])\n",
    "    z = np.array(csv_file.loc[:, ' Z_0':' Z_67'])\n",
    "\n",
    "    r_x = np.array(csv_file.loc[:, ' pose_Rx'])\n",
    "    r_y = np.array(csv_file.loc[:, ' pose_Ry'])\n",
    "    r_z = np.array(csv_file.loc[:, ' pose_Rz'])\n",
    "\n",
    "    x_new = x * (np.cos(r_z)*np.cos(r_y))[:, np.newaxis] \\\n",
    "            + y * (np.cos(r_z)*np.sin(r_y)*np.sin(r_x) + np.sin(r_z)*np.cos(r_x))[:, np.newaxis] \\\n",
    "            + z * (np.sin(r_z)*np.sin(r_x) - np.cos(r_z)*np.sin(r_y)*np.cos(r_x))[:, np.newaxis]\n",
    "    y_new = -x * (np.sin(r_z)*np.cos(r_y))[:, np.newaxis] \\\n",
    "            + y * (np.cos(r_z)*np.cos(r_x) - np.sin(r_z)*np.sin(r_y)*np.sin(r_x))[:, np.newaxis] \\\n",
    "            + z * (np.sin(r_z)*np.sin(r_y)*np.cos(r_x) + np.cos(r_z)*np.sin(r_x))[:, np.newaxis]\n",
    "\n",
    "    y_new = -y_new\n",
    "\n",
    "    #x_new = x.copy(); y_new = -y.copy()\n",
    "\n",
    "    #for every row find t_x, t_y, theta, and scale\n",
    "    l_e_x = np.mean(x_new[:, 36:42], axis=1)\n",
    "    l_e_y = np.mean(y_new[:, 36:42], axis=1)\n",
    "    r_e_x = np.mean(x_new[:, 42:48], axis=1)\n",
    "    r_e_y = np.mean(y_new[:, 42:48], axis=1)\n",
    "\n",
    "    #translate\n",
    "    x = x_new - l_e_x[:, np.newaxis]\n",
    "    y = y_new - l_e_y[:, np.newaxis]\n",
    "    r_e_x = r_e_x - l_e_x\n",
    "    r_e_y = r_e_y - l_e_y\n",
    "    l_e_x = l_e_x - l_e_x\n",
    "    l_e_y = l_e_y - l_e_y\n",
    "\n",
    "    #rotate theta, assumption r_e_x is positive\n",
    "    cos_theta = r_e_x / np.sqrt(r_e_x**2 + r_e_y**2)\n",
    "    sin_theta = np.sqrt(1 - cos_theta**2)\n",
    "    sin_theta[r_e_y<0] = -sin_theta[r_e_y<0]\n",
    "\n",
    "    x_new = x * cos_theta[:, np.newaxis] + y * sin_theta[:, np.newaxis]\n",
    "    y_new = y * cos_theta[:, np.newaxis] - x * sin_theta[:, np.newaxis]\n",
    "    x = x_new\n",
    "    y = y_new\n",
    "    #for every row find t_x, t_y, theta, and scale\n",
    "    l_e_x = np.mean(x_new[:, 36:42], axis=1)\n",
    "    l_e_y = np.mean(y_new[:, 36:42], axis=1)\n",
    "    r_e_x = np.mean(x_new[:, 42:48], axis=1)\n",
    "    r_e_y = np.mean(y_new[:, 42:48], axis=1)\n",
    "\n",
    "    #scale\n",
    "    x = x / r_e_x[:, np.newaxis]\n",
    "    y = y / r_e_x[:, np.newaxis]\n",
    "    l_e_x = l_e_x / r_e_x\n",
    "    l_e_y = l_e_y / r_e_x\n",
    "    r_e_y = r_e_y / r_e_x\n",
    "    r_e_x = r_e_x / r_e_x\n",
    "\n",
    "\n",
    "    if verbose:\n",
    "        fig = plt.figure()\n",
    "        for i in range(len(l_e_y)):\n",
    "            fig.clf()\n",
    "            plt.scatter(x[i, :], y[i, :], c='b', marker='.')\n",
    "            plt.scatter(l_e_x[i], l_e_y[i], c='r', marker='.')\n",
    "            plt.scatter(r_e_x[i], r_e_y[i], c='r', marker='.')\n",
    "            fig.canvas.draw()\n",
    "            plt.show()\n",
    "            plt.pause(0.001)\n",
    "            \n",
    "        plt.close(fig)\n",
    "\n",
    "    out_ar = dict()\n",
    "    out_ar['x'] = x\n",
    "    out_ar['y'] = y\n",
    "\n",
    "    return out_ar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0/13\n",
      "1/13\n",
      "2/13\n",
      "3/13\n",
      "4/13\n",
      "5/13\n",
      "6/13\n",
      "7/13\n",
      "8/13\n",
      "9/13\n",
      "10/13\n",
      "11/13\n",
      "12/13\n",
      "(119, 54)\n"
     ]
    }
   ],
   "source": [
    "#landmark hdf5\n",
    "h5file = h5py.File('pdm_imposter.hdf5', 'a')\n",
    "lbls = list(file_paths.keys()) #hdf5 file will have a separate group for each label\n",
    "avg_win = int(in_fps/out_fps)\n",
    "for i in lbls:\n",
    "    \n",
    "    print('{}/{}'.format(i, len(lbls)))\n",
    "    if str(i) in h5file.keys():\n",
    "        group = h5file[str(i)]\n",
    "    else:\n",
    "        group = h5file.create_group(str(i)) #create label specific group\n",
    "    vid_names = file_paths[i]\n",
    "    \n",
    "    for v in vid_names:\n",
    "        \n",
    "        db_name = v.split('/')[-1] # name of dataset\n",
    "        if db_name not in group.keys(): #do only if the file has not been processed\n",
    "\n",
    "            #the number of frames we will get from this video\n",
    "            full_csv = pd.read_csv(v + '.csv') # read the csv\n",
    "            \n",
    "            lndmrk = get_landmark(full_csv, verbose=False)\n",
    "            x = lndmrk['x']\n",
    "            y = lndmrk['y']\n",
    "            \n",
    "            p = np.array(full_csv.loc[:, ' p_0':' p_33'])\n",
    "            aus = np.array(full_csv.loc[:, ' AU01_r':' AU45_r'])\n",
    "            r_xyz = np.array(full_csv.loc[:, ' pose_Rx':' pose_Rz'])\n",
    "            \n",
    "            #out_lndmrk = np.concatenate((x, y, aus, r_xyz), axis=1)\n",
    "            out_lndmrk = np.concatenate((p, aus, r_xyz), axis=1)\n",
    "            out_frame_cnt = int(np.floor(len(out_lndmrk)*out_fps/in_fps))\n",
    "            out_lndmrk = out_lndmrk[:(out_frame_cnt*avg_win), :]\n",
    "            \n",
    "            out_lndmrk = np.squeeze(np.mean(np.reshape(out_lndmrk, (out_frame_cnt, avg_win, out_lndmrk.shape[1])), \n",
    "                                            axis=1))\n",
    "            \n",
    "            if 0:#np.random.choice(range(100000), 1)[0] == 0:\n",
    "                clear_output(wait=True)\n",
    "                plt.figure()\n",
    "                plt.plot(out_lndmrk[:, 0:68], out_lndmrk[:, 68:136])\n",
    "                plt.title(i)\n",
    "                plt.axis('equal')\n",
    "                plt.show();\n",
    "                print('\\t {} {}/{}'.format(v, len(out_lndmrk), len(aus)))\n",
    "                plt.pause(0.5)\n",
    "                \n",
    "            # create the dataset with the complete groups with chunksize \n",
    "            data = group.create_dataset(db_name, out_lndmrk.shape, dtype='f4',\n",
    "                                        compression=\"gzip\", compression_opts=4)\n",
    "            data[:] = out_lndmrk\n",
    "            h5file.flush() #write out the file\n",
    "\n",
    "print(out_lndmrk.shape)\n",
    "h5file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Spectrograms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#audio hdf5\n",
    "h5file = h5py.File('audio.hdf5', 'a')\n",
    "lbls = list(file_paths.keys()) #hdf5 file will have a separate group for each label\n",
    "avg_win = int(in_fps/out_fps)\n",
    "for i in lbls:\n",
    "    \n",
    "    if str(i) in h5file.keys():\n",
    "        group = h5file[str(i)]\n",
    "    else:\n",
    "        group = h5file.create_group(str(i)) #create label specific group\n",
    "    vid_names = file_paths[i]\n",
    "    \n",
    "    for v in vid_names:\n",
    "        \n",
    "        db_name = v.split('/')[-1] # name of dataset\n",
    "        if db_name not in group.keys(): #do only if the file has not been processed\n",
    "\n",
    "            #the number of frames we will get from this video\n",
    "            audio, sample_rate = librosa.load(v + '.wav')# read the audio feel\n",
    "            spectrum = np.abs(librosa.stft(audio, n_fft=n_fft, \n",
    "                                    hop_length=int(sample_rate*sfft_hop), \n",
    "                                    win_length=int(sample_rate*sfft_wl), \n",
    "                                   center=False).T)\n",
    "            \n",
    "            # create the dataset with the complete groups with chunksize \n",
    "            data = group.create_dataset(db_name, spectrum.shape, dtype='f4', compression=\"gzip\", compression_opts=4)\n",
    "            if True:\n",
    "                plt.imshow('sfft', spectrum)\n",
    "                plt.show()\n",
    "            data[:] = spectrum\n",
    "            \n",
    "            h5file.flush() #write out the file\n",
    "\n",
    "h5file.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
